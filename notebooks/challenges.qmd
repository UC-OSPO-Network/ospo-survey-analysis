---
title: "Challenges"
---

# Overview

Initial analysis of survey Q9: "How frequently have you encountered the following challenges while working on open-source projects?"

## Import packages and utilities
```{r}
project_root <- here::here() # requires that you be somewhere in the
# project directory (not above it)
# packages
suppressMessages(source(file.path(project_root, "scripts/packages.R")))
# functions and objects used across scripts
suppressMessages(source(file.path(project_root, "scripts/utils.R")))
```

## Set seed
```{r}
set.seed(42)
```

## Define functions

#### multiple_plots
- Arguments:
  - `df`: In this script, this will always be the `to_plot` data frame.
    Must contain (at least) three columns: `challenge`, `challenge_level`
    (a character column), and `total`.
  - `title_codes`: In this script, this will always be the `titles` list.
    Keys are shorthand codes for each challenge, and values are the full
    challenge from the survey.
  - `challenges_of_interest`: A character vector of the challenges you
    want to plot.
- Details:
  - A simple function to call my `basic_bar_chart` function (from 
    scripts/utils.R) on multiple challenges, producing multiple plots.
- Outputs:
  - Prints n plots, where n is the number of challenges of interest.
```{r}
multiple_plots <- function(df, title_codes, challenges_of_interest) {
  for (ch in challenges_of_interest) {
    df_ch <- filter(df, challenge == ch)
    plot_title <- title_codes[[ch]]
    p <- basic_bar_chart(
      df_ch,
      x_var = "challenge_level",
      y_var = "total",
      title = plot_title,
      show_grid = TRUE
    )
    print(p)
  }
}
```

## Load data
```{r}
challenges <- load_qualtrics_data("clean_data/challenges_Q9.tsv")
```

## Wrangle data
Remove empty rows, i.e. rows from respondents who didn't receive this question. As with many questions in this survey, we can cut some corners in the code because the question was mandatory. For example, no need to worry about incomplete answers.
```{r}
nrow(challenges)
challenges <- exclude_empty_rows(challenges) # from scripts/utils.R
nrow(challenges)
```

Let's reshape the data from wide to long format for easier plotting later. We'll also recode the Likert values to integers, so we can get descriptive statistics of the responses. ("Never" = 0, "Non-applicable"  = 0,"Rarely" = 1, "Occasionally" = 2, "Frequently" = 3, "Always" = 4)
```{r}
long_data <- challenges %>%
  pivot_longer(
    cols = everything(),
    names_to = "challenge",
    values_to = "challenge_level"
  )

long_data <- long_data %>%
  mutate(
    challenge_score = recode(
      challenge_level,
      "Never"           = 0L,
      "Non-applicable"  = 0L,
      "Rarely"          = 1L,
      "Occasionally"    = 2L,
      "Frequently"      = 3L,
      "Always"          = 4L
    )
  )
# Using interger literals 0L, 1L, etc., ensures that
# the new column will be integers, not doubles.

long_data
```

Next, let's calculate some simple descriptive statistics. I will choose:\
* The total "score", that is, the total number of "points" a challenge received
* The mean (which might be misleading if 0s drag it down, and also, who's to say what a 2.5 really means? Are the distances between the Likert points equal? We assume so, but this is hand-wavy.)
* The mode
* The standard deviation
```{r}
# Helper to compute the (numeric) mode
get_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

summary_df <- long_data %>%
  group_by(challenge) %>%
  summarise(
    total  = sum(challenge_score),
    mean   = mean(challenge_score, na.rm = TRUE),
    mode   = get_mode(challenge_score),
    st_dev = sd(challenge_score, na.rm = TRUE)
  ) %>%
  ungroup()

# Order by highest total "score"
summary_df <- summary_df %>%
    arrange(desc(total))

summary_df
```

Cool! It looks like finding the time for documentation, coding, and self-education are the challenges encountered most frequently. These are the only responses that had a mode of 3 ("Frequently") and a mean of __greater__ than 2 ("Occasionally").

Out of curiosity, how does it look when we order by variability?
```{r}
sd_df <- summary_df %>%
    arrange(desc(st_dev))

sd_df
```

Fascinating! The greatest standard deviations are from securing funding, finding funding, and hiring. This makes sense, as these are, at least in my perception, "manager tasks"--tasks that only some people face, but they're likely to be a big challenge for those who face them. I would guess that these might show a bimodal distribution. Let's plot them and find out!

# Plot the distributions
Prepare data for plotting
```{r}
ordered_levels <- c(
  "Non-applicable",
  "Never",
  "Rarely",
  "Occasionally",
  "Frequently",
  "Always"
)

to_plot <- long_data %>%
  mutate(
    challenge_level = factor(
      challenge_level,
      levels = ordered_levels
    )
  ) %>%
  count(
    challenge,
    challenge_level,
    name = "total"
  ) %>%
  ungroup()

to_plot
```

Create a plot for each "challenge". After inspecting the plots, I attempted to order them into groups based on the shape of their distribution. These are the shapes I observed (this is extremely subjective):\
* Right-skewed: Documentation time, coding time, education time
  * Interpretation: Common tasks that are frequently challenging
* Highly bimodal: Securing funding, identifying funding, hiring
  * Interpretation: Tasks that are not as common, but they are frequently challenging for the people tasked with them.
* Normal: Educational resources, Legal
  * Interpretation: Moderately common tasks that are challenging with moderate frequency.
* NA-skewed but otherwise normal: Attracting users, Receiving recognition, finding mentors, managing security risks, managing issues
  * Interpretation: Less-common tasks that are challenging with moderate frequency.
* Left-skewed: Finding peers
  * Interpretation: Moderately common tasks that are infrequently challenging.
```{r}
titles <- list(
    "Coding time" = "Limited time for writing new code",
    "Documentation time" = "Limited time for writing documentation",
    "Managing issues" = "Managing issues and pull requests",
    "Attracting users" = "Attracting users and/or contributors",
    "Recognition" = "Receiving recognition for my contributions",
    "Hiring" = "Finding and hiring qualified personnel",
    "Security" = "Managing security risks",
    "Finding peers" = "Finding a community of peers who share my interests",
    "Finding mentors" = "Finding mentors",
    "Education time" = "Finding time to educate myself",
    "Educational resources" = "Identifying helpful educational resources",
    "Legal" = "Navigating licensing and other legal issues",
    "Finding funding" = "Identifying potential funding sources\nfor my open source projects",
    "Securing funding" = "Securing funding for my open source projects"
)

right_skewed <- c(
    "Coding time",
    "Documentation time",
    "Education time"
)
bimodal <- c(
    "Finding funding",
    "Securing funding",
    "Hiring"
)
normal <- c(
    "Educational resources",
    "Legal"
)
na_skewed <- c(
    "Managing issues",
    "Attracting users",
    "Recognition",
    "Security",
    "Finding mentors"
)
left_skewed <- c(
    "Finding peers"
)

```

### "right-skewed"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, right_skewed)
```

### "highly bimodal"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, bimodal)
```

### "normal"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, normal)
```

### "na-skewed"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, na_skewed)
```

### "left-skewed"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, left_skewed)
```

# K-means clustering of distributions
This seems like an interesting line of inquiry. Let's make it a little more rigorous by clustering the challenges based on the response rates (actually, the absolute response numbers).

## Wrangle data
```{r}
wide_counts <- to_plot %>%
  pivot_wider(
    names_from   = challenge_level,
    values_from  = total,
    values_fill  = 0
  )

wide_counts <- data.frame(wide_counts)
# Turn this categorical column into row names
rownames(wide_counts) <- wide_counts$challenge
wide_counts <- wide_counts[,2:(ncol(wide_counts))]

# Scaling probably isn't necessary?
# We have the same number of responses throughout,
# so the units for each challenge are the same
# (number of responses).
scaled <- scale(wide_counts)
scaled
```

Plot an elbow plot to find the point of diminishing returns.
```{r, fig.width=9, fig.height=6}
factoextra::fviz_nbclust(scaled, kmeans, method = "wss")
```

I seem to get diminishing returns around k=4.
```{r, fig.width=9, fig.height=6}
factoextra::fviz_nbclust(scaled, kmeans, method = "silhouette")
```

Hm. The silhouette plot indicates I should use k=3.

I think I'll try k=4 first, since it's closer to the number I got from eyeballing. Let's look at a different type of silhouette plot, which shows us the silhouette width of each cluster and on average across the clusters.
```{r, fig.width=9, fig.height=6}
km <- kmeans(scaled, centers = 4, nstart = 25)
dist_mat <- dist(scaled)
sil <- cluster::silhouette(km$cluster, dist_mat)
plot(sil)
```

Hm. Looks... acceptable. From Wikipedia: "A clustering with an average silhouette width of over 0.7 is considered to be "strong", a value over 0.5 "reasonable" and over 0.25 "weak"." Let's try unscaled data.
```{r, fig.width=9, fig.height=6}
km <- kmeans(wide_counts, centers = 4, nstart = 25)
dist_mat <- dist(wide_counts)
sil <- cluster::silhouette(km$cluster, dist_mat)
plot(sil)
```

Looks slightly worse. Still, I think we should probably stick with unscaled data because it's simpler, and I don't think we should add extra unnecessary procedures. What if we try 3 clusters?
```{r, fig.width=9, fig.height=6}
km <- kmeans(wide_counts, centers = 3, nstart = 25)
dist_mat <- dist(wide_counts)
sil <- cluster::silhouette(km$cluster, dist_mat)
plot(sil)
```

With an average silhouette width of 0.43-0.47, our clusters aren't looking amazing. But they're not terrible, either. I prefer to use unscaled data with k=3, which results in an average silhouette score of 0.47. I think these results are consistent with my hunch that the data for the challenges are not all drawn from the same distribution. These are the cluster assignments:
```{r}
# A little extra code to achieve prettier printing
cluster_df <- data.frame(sort(km$cluster))
cluster_df$challenge <- rownames(cluster_df)
clusters <- unique(cluster_df[,1])
for (cl in clusters) {
  print(cluster_df[cluster_df[,1] == cl,], row.names = FALSE)
  cat("\n")
}
```

Let's look at a silhouette plot for the PAM method, too.
```{r, fig.width=9, fig.height=6}
factoextra::fviz_nbclust(wide_counts, FUNcluster = pam, method = "silhouette")
```

This also says that 3 clusters is ideal.

Let's try PAM clustering on the unscaled data with k=3.
```{r}
pm <- cluster::pam(wide_counts, k=3)
```

Print the clusters in a more readable format.
```{r}
cluster_df <- data.frame(sort(pm$cluster))
cluster_df$challenge <- rownames(cluster_df)
clusters <- unique(cluster_df[,1])
for (cl in clusters) {
  print(cluster_df[cluster_df[,1] == cl,], row.names = FALSE)
  cat("\n")
}
```

We see the same groups we saw with k-means clustering. Good! 

One last check: what about a stability assessment by bootstrap resampling?
```{r results="hide"}
# Note I'm hiding the printed status update from each iteration
boot_res <- fpc::clusterboot(
  wide_counts,
  clustermethod = fpc::kmeansCBI,
  krange = 3
)
# Annoyingly, the documentation doesn't explain 'krange',
# but I'm pretty sure that this argument lets you specify
# a desired k or range of k values (e.g. 5:7)
```

```{r}
boot_res
mean(boot_res$bootmean)
```
The clusterwise Jaccard bootstrap means are around 0.8-0.9, which is pretty respectable.
Although this analysis was brief, I think we can conclude that these three clusters are reasonably stable and meaningful.

# PCA (Abandoned)
In the above sections, I was clustering challenges into groups. Here, I started clustering people into groups. However, this didn't seem too promising, and I don't know if I care enough to pursue it.
NOTE THE DIFFERENT CODING SCHEME
```{r, fig.width=6, fig.height=6}
challnumeric <- challenges %>%
  mutate(
    across(
      everything(),
      ~ recode(
        .x,
        "Never" = 0L,
        "Non-applicable" = -1L, # THIS IS DIFFERENT (-1, not 0)
        "Rarely" = 1L,
        "Occasionally" = 2L,
        "Frequently" = 3L,
        "Always" = 4L
      )
    )
  )


pca <- prcomp(challnumeric, scale = TRUE)
summary(pca)
biplot(pca)
```
