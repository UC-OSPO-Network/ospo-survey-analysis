---
title: "Challenges"
---

# Overview

Unfinished analysis of survey Q9: "How frequently have you encountered the following challenges while working on open-source projects?"

## Import packages and utilities

```{r}
project_root <- here::here() # requires that you be somewhere in the
# project directory (not above it)
# packages
suppressMessages(source(file.path(project_root, "scripts/packages.R")))
# functions and objects used across scripts
suppressMessages(source(file.path(project_root, "scripts/utils.R")))
```

## Load data

```{r}
data <- load_qualtrics_data("deidentified_no_qual.tsv")
```

## Wrangle data

```{r}
challenges <- data %>%
  select(
    starts_with("challenges")
  )

head(challenges)
```

**STOP!!** Presumably, "challenges_1" corresponds to the first option, "challenges_2" corresponds to the second option, etc. But we still need to check. I am manually comparing the answers in this data frame to those in the Qualtrics interface, which shows the whole response, i.e. "Limited time for writing new code", not just "challenges_1". To be extra confident that I am comparing the same rows between the two tables, I am looking at responses associated with a particular email. After this code chunk, I go back to using the data frame that doesn't contain the emails.

Since this code only needed to be run once, I've commented it out.
```{r}
# pii <- load_qualtrics_data("pii.tsv")
# emails <- pii %>%
#     select(starts_with("stay_in_touch_email"))

# t <- cbind(emails, challenges)

# # Next, I run this line repeatedly with different emails,
# # to make sure that this person's response to "challenges_1"
# # matches their response to "Limited time for writing new code", etc.
# subset(t, startsWith(stay_in_touch_email, "PERSON_EMAIL_HERE"))
```

Next, remove empty rows, i.e. rows from respondents who didn't receive this question.
```{r}
nrow(challenges)
challenges <- exclude_empty_rows(challenges) # from scripts/utils.R
nrow(challenges)
```


```{r}
long_data <- challenges %>%
  pivot_longer(
    cols = starts_with("challenges"),
    names_to = "challenge",
    values_to = "challenge_level"
  )

long_data <- long_data %>%
  mutate(
    challenge = recode(
      challenge,
      "challenges_1" = "Coding time",
      "challenges_2" = "Documentation time",
      "challenges_3" = "Managing issues",
      "challenges_4" = "Attracting users",
      "challenges_5" = "Recognition",
      "challenges_6" = "Hiring",
      "challenges_7" = "Security",
      "challenges_8" = "Finding peers",
      "challenges_9" = "Finding mentors",
      "challenges_10" = "Education time",
      "challenges_11" = "Educational resources",
      "challenges_12" = "Legal",
      "challenges_13" = "Finding funding",
      "challenges_14" = "Securing funding"
    )
  )

long_data <- long_data %>%
  mutate(
    challenge_score = recode(
      challenge_level,
      "Never"           = 0L,
      "Non-applicable"  = 0L,
      "Rarely"          = 1L,
      "Occasionally"    = 2L,
      "Frequently"      = 3L,
      "Always"          = 4L
    )
  )
# Using interger literals 0L, 1L, etc., ensures that
# the new column will be integers, not doubles.
# We can get away with not checking for unmapped values
# because this question was mandatory.

long_data
```


```{r}
# Helper to compute the (numeric) mode
get_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

summary_df <- long_data %>%
  group_by(challenge) %>%
  summarise(
    total  = sum(challenge_score),
    mean   = mean(challenge_score, na.rm = TRUE),
    mode   = get_mode(challenge_score),
    st_dev = sd(challenge_score, na.rm = TRUE)
  ) %>%
  ungroup()

# Order by highest total "score"
summary_df <- summary_df %>%
    arrange(desc(total))

summary_df
```

Cool! It looks like finding the time for documentation, coding, and self-education are the challenges encountered most frequently. These are the only responses that had a mode of 3 ("Frequently") and a mean of __greater__ than 2 ("Occasionally").

Out of curiosity, how does it look when we order by variability?
```{r}
sd_df <- summary_df %>%
    arrange(desc(st_dev))

sd_df
```

Fascinating! The greatest standard deviations are from securing funding, finding funding, and hiring. This makes sense, as these are, at least in my perception, "manager tasks"--tasks that only some people face, but they're likely to be a big challenge for those who face them. I would guess that these might show a bimodal distribution. Let's plot them and find out!

# Plot the distributions

Prepare data for plotting
```{r}
ordered_levels <- c(
  "Non-applicable",
  "Never",
  "Rarely",
  "Occasionally",
  "Frequently",
  "Always"
)

to_plot <- long_data %>%
  mutate(challenge_level = factor(challenge_level, levels = ordered_levels)) %>%
  count(
    challenge,
    challenge_level,
    name = "total"
  ) %>%
  ungroup()

to_plot
```

```{r}
t <- to_plot %>%
  filter(
    challenge == "Documentation time"
  )

basic_bar_chart(
  t,
  x_var = "challenge_level",
  y_var = "total",
  title = "Limited time for writing documentation"
)
```