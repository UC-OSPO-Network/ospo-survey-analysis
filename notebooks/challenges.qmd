---
title: "Challenges"
---

# Overview

Initial analysis of survey Q9: "How frequently have you encountered the following challenges while working on open-source projects?"

## Import packages and utilities

```{r}
project_root <- here::here() # requires that you be somewhere in the
# project directory (not above it)
# packages
suppressMessages(source(file.path(project_root, "scripts/packages.R")))
# functions and objects used across scripts
suppressMessages(source(file.path(project_root, "scripts/utils.R")))
```

## Load data

```{r}
data <- load_qualtrics_data("deidentified_no_qual.tsv")
```

## Wrangle data

```{r}
challenges <- data %>%
  select(
    starts_with("challenges")
  )

head(challenges)
```

**STOP!!** Presumably, "challenges_1" corresponds to the first option, "challenges_2" corresponds to the second option, etc., but we still need to check. I am manually comparing the answers in this data frame to those in the Qualtrics interface, which shows the whole response, i.e. "Limited time for writing new code", not just "challenges_1". To be extra confident that I am comparing the same rows between the two tables, I am looking at responses associated with a particular email. After this code chunk, I go back to using the data frame that doesn't contain the emails.

Since this code only needed to be run once, I've commented it out.
```{r}
# pii <- load_qualtrics_data("pii.tsv")
# emails <- pii %>%
#     select(starts_with("stay_in_touch_email"))

# t <- cbind(emails, challenges)

# # Next, I run this line repeatedly with different emails,
# # to make sure that this person's response to "challenges_1"
# # matches their response to "Limited time for writing new code", etc.
# subset(t, startsWith(stay_in_touch_email, "PERSON_EMAIL_HERE"))
```
My assumption above was correct; the options are ordered as expected.

Next, remove empty rows, i.e. rows from respondents who didn't receive this question. As with many questions in this survey, we can cut some corners in the code because the question was mandatory. For example, no need to worry about incomplete answers.
```{r}
nrow(challenges)
challenges <- exclude_empty_rows(challenges) # from scripts/utils.R
nrow(challenges)
```

Let's reshape the data from wide to long format for easier plotting later.
```{r}
long_data <- challenges %>%
  pivot_longer(
    cols = starts_with("challenges"),
    names_to = "challenge",
    values_to = "challenge_level"
  )

long_data <- long_data %>%
  mutate(
    challenge = recode(
      challenge,
      "challenges_1" = "Coding time",
      "challenges_2" = "Documentation time",
      "challenges_3" = "Managing issues",
      "challenges_4" = "Attracting users",
      "challenges_5" = "Recognition",
      "challenges_6" = "Hiring",
      "challenges_7" = "Security",
      "challenges_8" = "Finding peers",
      "challenges_9" = "Finding mentors",
      "challenges_10" = "Education time",
      "challenges_11" = "Educational resources",
      "challenges_12" = "Legal",
      "challenges_13" = "Finding funding",
      "challenges_14" = "Securing funding"
    )
  )

long_data <- long_data %>%
  mutate(
    challenge_score = recode(
      challenge_level,
      "Never"           = 0L,
      "Non-applicable"  = 0L,
      "Rarely"          = 1L,
      "Occasionally"    = 2L,
      "Frequently"      = 3L,
      "Always"          = 4L
    )
  )
# Using interger literals 0L, 1L, etc., ensures that
# the new column will be integers, not doubles.

long_data
```

Next, let's calculate some simple descriptive statistics. I will choose:
* The total "score", that is, the total number of "points" a challenge received ("Never" = 0, "Non-applicable"  = 0,"Rarely" = 1, "Occasionally" = 2, "Frequently" = 3, "Always" = 4)
* The mean (which might be misleading if 0s drag it down, and also, who's to say what a 2.5 really means? Are the distances between the Likert points equal? We don't know.)
* The mode
* The standard deviation
```{r}
# Helper to compute the (numeric) mode
get_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

summary_df <- long_data %>%
  group_by(challenge) %>%
  summarise(
    total  = sum(challenge_score),
    mean   = mean(challenge_score, na.rm = TRUE),
    mode   = get_mode(challenge_score),
    st_dev = sd(challenge_score, na.rm = TRUE)
  ) %>%
  ungroup()

# Order by highest total "score"
summary_df <- summary_df %>%
    arrange(desc(total))

summary_df
```

Cool! It looks like finding the time for documentation, coding, and self-education are the challenges encountered most frequently. These are the only responses that had a mode of 3 ("Frequently") and a mean of __greater__ than 2 ("Occasionally").

Out of curiosity, how does it look when we order by variability?
```{r}
sd_df <- summary_df %>%
    arrange(desc(st_dev))

sd_df
```

Fascinating! The greatest standard deviations are from securing funding, finding funding, and hiring. This makes sense, as these are, at least in my perception, "manager tasks"--tasks that only some people face, but they're likely to be a big challenge for those who face them. I would guess that these might show a bimodal distribution. Let's plot them and find out!

# Plot the distributions
Prepare data for plotting
```{r}
ordered_levels <- c(
  "Non-applicable",
  "Never",
  "Rarely",
  "Occasionally",
  "Frequently",
  "Always"
)

to_plot <- long_data %>%
  mutate(challenge_level = factor(challenge_level, levels = ordered_levels)) %>%
  count(
    challenge,
    challenge_level,
    name = "total"
  ) %>%
  ungroup()

to_plot
```

Create a plot for each "challenge"
```{r}
titles <- list(
    "Coding time" = "Limited time for writing new code",
    "Documentation time" = "Limited time for writing documentation",
    "Managing issues" = "Managing issues and pull requests",
    "Attracting users" = "Attracting users and/or contributors",
    "Recognition" = "Receiving recognition for my contributions",
    "Hiring" = "Finding and hiring qualified personnel",
    "Security" = "Managing security risks",
    "Finding peers" = "Finding a community of peers who share my interests",
    "Finding mentors" = "Finding mentors",
    "Education time" = "Finding time to educate myself",
    "Educational resources" = "Identifying helpful educational resources",
    "Legal" = "Navigating licensing and other legal issues",
    "Finding funding" = "Identifying potential funding sources\nfor my open source projects",
    "Securing funding" = "Securing funding for my open source projects"
)


for (ch in unique(summary_df$challenge)) { 
    # use summary_df to get ordered levels
  df_ch <- filter(to_plot, challenge == ch)
  plot_title <- titles[[ch]]
  p <- basic_bar_chart(
    df_ch,
    x_var     = "challenge_level",
    y_var     = "total",
    title     = plot_title,
    show_grid = TRUE
  )
  print(p) # need to explicitly print
}

```