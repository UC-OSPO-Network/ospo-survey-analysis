---
title: "Challenges"
---

# Overview

Initial analysis of survey Q9: "How frequently have you encountered the following challenges while working on open-source projects?"

## Import packages and utilities
```{r}
project_root <- here::here() # requires that you be somewhere in the
# project directory (not above it)
# packages
suppressMessages(source(file.path(project_root, "scripts/packages.R")))
# functions and objects used across scripts
suppressMessages(source(file.path(project_root, "scripts/utils.R")))
```

## Set seed
```{r}
set.seed(42)
```

## Define functions

#### multiple_plots
- Arguments:
  - `df`: In this script, this will always be the `to_plot` data frame.
    Must contain (at least) three columns: `challenge`, `challenge_level`
    (a character column), and `total`.
  - `title_codes`: In this script, this will always be the `titles` list.
    Keys are shorthand codes for each challenge, and values are the full
    challenge from the survey.
  - `challenges_of_interest`: A character vector of the challenges you
    want to plot.
- Details:
  - A simple function to call my `basic_bar_chart` function (from 
    scripts/utils.R) on multiple challenges, producing multiple plots.
- Outputs:
  - Prints n plots, where n is the number of challenges of interest.
```{r}
multiple_plots <- function(df, title_codes, challenges_of_interest) {
  for (ch in challenges_of_interest) {
    df_ch <- filter(df, challenge == ch)
    plot_title <- title_codes[[ch]]
    p <- basic_bar_chart(
      df_ch,
      x_var = "challenge_level",
      y_var = "total",
      title = plot_title,
      show_grid = TRUE
    )
    print(p)
  }
}
```

## Load data
```{r}
challenges <- load_qualtrics_data("clean_data/challenges_Q9.tsv")
```

## Wrangle data
Remove empty rows, i.e. rows from respondents who didn't receive this question. As with many questions in this survey, we can cut some corners in the code because the question was mandatory. For example, no need to worry about incomplete answers.
```{r}
nrow(challenges)
challenges <- exclude_empty_rows(challenges) # from scripts/utils.R
nrow(challenges)
```

Let's reshape the data from wide to long format for easier plotting later. We'll also recode the Likert values to integers, so we can get descriptive statistics of the responses. ("Never" = 0, "Non-applicable"  = 0,"Rarely" = 1, "Occasionally" = 2, "Frequently" = 3, "Always" = 4)
```{r}
long_data <- challenges %>%
  pivot_longer(
    cols = everything(),
    names_to = "challenge",
    values_to = "challenge_level"
  )

long_data <- long_data %>%
  mutate(
    challenge_score = recode(
      challenge_level,
      "Never"           = 0L,
      "Non-applicable"  = 0L,
      "Rarely"          = 1L,
      "Occasionally"    = 2L,
      "Frequently"      = 3L,
      "Always"          = 4L
    )
  )
# Using interger literals 0L, 1L, etc., ensures that
# the new column will be integers, not doubles.

long_data
```

Next, let's calculate some simple descriptive statistics. I will choose:\
* The total "score", that is, the total number of "points" a challenge received
* The mean (which might be misleading if 0s drag it down, and also, who's to say what a 2.5 really means? Are the distances between the Likert points equal? We assume so, but this is hand-wavy.)
* The median
* The mode
* The standard deviation
```{r}
# Helper to compute the (numeric) mode
get_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

summary_df <- long_data %>%
  group_by(challenge) %>%
  summarise(
    total  = sum(challenge_score),
    mean   = mean(challenge_score, na.rm = TRUE),
    median = median(challenge_score),
    mode   = get_mode(challenge_score),
    st_dev = sd(challenge_score, na.rm = TRUE)
  ) %>%
  ungroup()

# Order by highest total "score"
summary_df <- summary_df %>%
    arrange(desc(total))

summary_df
```

Cool! It looks like finding the time for documentation, coding, and self-education are the challenges encountered most frequently. These are the only responses that had a mode of 3 ("Frequently") and a mean of __greater__ than 2 ("Occasionally").

```{r}
# Prettify
summary_df_to_print <- summary_df %>%
  rename(
    `Challenge` = `challenge`,
    `Total` = `total`,
    `Mean` = `mean`,
    `Median` = `median`,
    `Mode` = `mode`,
    `Standard Deviation` = `st_dev`
  )

write_df_to_file(summary_df_to_print, "challenges.tsv")
```

Out of curiosity, how does it look when we order by variability?
```{r}
sd_df <- summary_df %>%
    arrange(desc(st_dev))

sd_df
```

Fascinating! The greatest standard deviations are from securing funding, finding funding, and hiring. This makes sense, as these are, at least in my perception, "manager tasks"--tasks that only some people face, but they're likely to be a big challenge for those who face them. I would guess that these might show a bimodal distribution. Let's plot them and find out!

# Plot the distributions
Prepare data for plotting
```{r}
ordered_levels <- c(
  "Non-applicable",
  "Never",
  "Rarely",
  "Occasionally",
  "Frequently",
  "Always"
)

to_plot <- long_data %>%
  mutate(
    challenge_level = factor(
      challenge_level,
      levels = ordered_levels
    )
  ) %>%
  count( # Count number of occurrences, 
  #i.e. number of people who selected that challenge level
    challenge,
    challenge_level,
    name = "total"
  ) %>%
  ungroup()

to_plot
```

Create a plot for each "challenge". After inspecting the plots, I attempted to order them into groups based on the shape of their distribution. These are the shapes I observed (this is extremely subjective):\
* Right-skewed: Documentation time, coding time, education time
  * Interpretation: Common tasks that are frequently challenging
* Highly bimodal: Securing funding, identifying funding, hiring
  * Interpretation: Tasks that are not as common, but they are frequently challenging for the people tasked with them.
* Normal: Educational resources, Legal
  * Interpretation: Moderately common tasks that are challenging with moderate frequency.
* NA-skewed but otherwise normal: Attracting users, Receiving recognition, finding mentors, managing security risks, managing issues
  * Interpretation: Less-common tasks that are challenging with moderate frequency.
* Left-skewed: Finding peers
  * Interpretation: Moderately common tasks that are infrequently challenging.
```{r}
titles <- list(
    "Coding time" = "Limited time for writing new code",
    "Documentation time" = "Limited time for writing documentation",
    "Managing issues" = "Managing issues and pull requests",
    "Attracting users" = "Attracting users and/or contributors",
    "Recognition" = "Receiving recognition for my contributions",
    "Hiring" = "Finding and hiring qualified personnel",
    "Security" = "Managing security risks",
    "Finding peers" = "Finding a community of peers who share my interests",
    "Finding mentors" = "Finding mentors",
    "Education time" = "Finding time to educate myself",
    "Educational resources" = "Identifying helpful educational resources",
    "Legal" = "Navigating licensing and other legal issues",
    "Finding funding" = "Identifying potential funding sources\nfor my open source projects",
    "Securing funding" = "Securing funding for my open source projects"
)

right_skewed <- c(
    "Coding time",
    "Documentation time",
    "Education time"
)
bimodal <- c(
    "Finding funding",
    "Securing funding",
    "Hiring"
)
normal <- c(
    "Educational resources",
    "Legal"
)
na_skewed <- c(
    "Managing issues",
    "Attracting users",
    "Recognition",
    "Security",
    "Finding mentors"
)
left_skewed <- c(
    "Finding peers"
)

```

### "right-skewed"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, right_skewed)
```

### "highly bimodal"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, bimodal)
```

### "normal"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, normal)
```

### "na-skewed"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, na_skewed)
```

### "left-skewed"
```{r, fig.width=9, fig.height=6}
multiple_plots(to_plot, titles, left_skewed)
```

# K-means clustering of distributions
This seems like an interesting line of inquiry. Let's make it a little more rigorous by clustering the challenges based on the response rates (actually, the absolute response numbers).

## Wrangle data
```{r}
wide_counts <- to_plot %>%
  pivot_wider(
    names_from   = challenge_level,
    values_from  = total,
    values_fill  = 0
  )

wide_counts <- data.frame(wide_counts)
# Turn this categorical column into row names
rownames(wide_counts) <- wide_counts$challenge
wide_counts <- wide_counts[,2:(ncol(wide_counts))]
head(wide_counts)

# Scaling probably isn't necessary?
# We have the same number of responses throughout,
# so the units for each challenge are the same
# (number of responses).
scaled <- scale(wide_counts)
scaled
```

Plot an elbow plot to find the point of diminishing returns.
```{r, fig.width=9, fig.height=6}
factoextra::fviz_nbclust(scaled, kmeans, method = "wss")
```

I seem to get diminishing returns around k=4.
```{r, fig.width=9, fig.height=6}
factoextra::fviz_nbclust(scaled, kmeans, method = "silhouette")
```

Hm. The silhouette plot indicates I should use k=3.

I think I'll try k=4 first, since it's closer to the number I got from eyeballing. Let's look at a different type of silhouette plot, which shows us the silhouette width of each cluster and on average across the clusters.
```{r, fig.width=9, fig.height=6}
km <- stats::kmeans(scaled, centers = 4, nstart = 25)
dist_mat <- dist(scaled)
sil <- cluster::silhouette(km$cluster, dist_mat)
plot(sil)
```

Hm. Looks... acceptable. Average silhouette width of 0.47. From Wikipedia: "A clustering with an average silhouette width of over 0.7 is considered to be "strong", a value over 0.5 "reasonable" and over 0.25 "weak"." Let's try unscaled data.
```{r, fig.width=9, fig.height=6}
km <- stats::kmeans(wide_counts, centers = 4, nstart = 25)
dist_mat <- dist(wide_counts)
sil <- cluster::silhouette(km$cluster, dist_mat)
plot(sil)
```

Looks slightly worse: average silhouette width = 0.43. Still, I think we should probably stick with unscaled data because it's simpler, and I don't think we should add extra unnecessary procedures. What if we try 3 clusters?
```{r, fig.width=9, fig.height=6}
km <- stats::kmeans(wide_counts, centers = 3, nstart = 25)
dist_mat <- dist(wide_counts)
sil <- cluster::silhouette(km$cluster, dist_mat)
plot(sil)
```

With an average silhouette width of 0.44-0.52, our clusters aren't looking amazing (unscaled data, 3 clusters). But they're not terrible, either. I prefer to use unscaled data with k=3, which results in an average silhouette width of 0.47. I think these results are consistent with my hunch that the data for the challenges are not all drawn from the same distribution. These are the cluster assignments:
```{r}
# A little extra code to achieve prettier printing
cluster_df <- data.frame(sort(km$cluster))
cluster_df$challenge <- rownames(cluster_df)
clusters <- unique(cluster_df[,1])
for (cl in clusters) {
  print(cluster_df[cluster_df[,1] == cl,], row.names = FALSE)
  cat("\n")
}
```

Let's look at a silhouette plot for the PAM method, too.
```{r, fig.width=9, fig.height=6}
factoextra::fviz_nbclust(wide_counts, FUNcluster = pam, method = "silhouette")
```

This also says that 3 clusters is ideal.

Let's try PAM clustering on the unscaled data with k=3.
```{r}
pm <- cluster::pam(wide_counts, k=3)
```

Print the clusters in a more readable format.
```{r}
cluster_df <- data.frame(sort(pm$cluster))
cluster_df$challenge <- rownames(cluster_df)
clusters <- unique(cluster_df[,1])
for (cl in clusters) {
  print(cluster_df[cluster_df[,1] == cl,], row.names = FALSE)
  cat("\n")
}
```

We see the same groups we saw with k-means clustering. Good! 

One last check: what about a stability assessment by bootstrap resampling?
```{r results="hide"}
# Note I'm hiding the printed status update from each iteration
boot_res <- fpc::clusterboot(
  wide_counts,
  clustermethod = fpc::kmeansCBI,
  krange = 3
)
# Annoyingly, the documentation doesn't explain 'krange',
# but I'm pretty sure that this argument lets you specify
# a desired k or range of k values (e.g. 5:7)
```

```{r}
boot_res
mean(boot_res$bootmean)
```
The clusterwise Jaccard bootstrap means are around 0.8-0.9, which is pretty respectable.
Although this analysis was brief, I think we can conclude that these three clusters are reasonably stable and meaningful.

# Stacked bar plots
A request from Amber: how about color-coded stacked bar plots, instead of the bar charts I made above?

```{r}
# Rename this column, poorly named by the cluster package
# From `sort.km.cluster.` to sort_km_cluster
names(cluster_df)[1] <- "sort_km_cluster"

temp <- to_plot
temp$challenge_level <- factor(temp$challenge_level, levels = rev(ordered_levels))

data_cluster1 <- temp %>%
  filter(
      challenge %in% rownames(subset(cluster_df, sort_km_cluster == 1)
    )
  )

data_cluster2 <- temp %>%
  filter(
      challenge %in% rownames(subset(cluster_df, sort_km_cluster == 2)
    )
  )

data_cluster3 <- temp %>%
  filter(
      challenge %in% rownames(subset(cluster_df, sort_km_cluster == 3)
    )
  )
```

WARNING! I am changing the cluster names ONLY on the plot, not in the rest of the code. The plot looks better when the two small clusters--clusters 1 and 3--are next to each other (we want to visually compare them, and it's easier to do so when they're adjacent). However, the plot looks dumb when I have them in order 1, 3, 2. It looks like I made a mistake. So I am renaming the plot panel titles ONLY.

```{r}
# Paul Tol's sunset theme
#https://sronpersonalpages.nl/~pault/
sunset <- c(
  "#A50026",
  "#F67E4B",
  "#FEDA8B",
  "#C2E4EF",
  "#6EA6CD",
  "#364B9A"
)

p1 <- stacked_bar_chart(
  df = data_cluster2,
  x_var = "challenge",
  y_var = "total",
  fill = "challenge_level",
  title = "Cluster 1", # NAME CHANGE, SEE TEXT ABOVE
  ylabel = NULL,
  show_axis_title_y = FALSE,
  show_x_axis_text = FALSE,
  show_grid = TRUE,
  show_legend = FALSE, # don't show legend
  horizontal = TRUE,
  proportional = TRUE,
  cpalette = sunset
)

p2 <- stacked_bar_chart(
  df = data_cluster3,
  x_var = "challenge",
  y_var = "total",
  fill = "challenge_level",
  title = "Cluster 2", # NAME CHANGE, SEE TEXT ABOVE
  ylabel = NULL,
  legend_left_margin = 45, # show legend, with a wide margin
  show_axis_title_y = FALSE,
  show_x_axis_text = FALSE,
  show_grid = TRUE,
  horizontal = TRUE,
  proportional = TRUE,
  cpalette = sunset
)

p3 <- stacked_bar_chart(
  df = data_cluster1,
  x_var = "challenge",
  y_var = "total",
  fill = "challenge_level",
  title = "Cluster 3", # NAME CHANGE, SEE TEXT ABOVE
  ylabel = NULL,
  show_axis_title_y = FALSE,
  show_x_axis_text = FALSE,
  show_grid = TRUE,
  show_legend = FALSE, # don't show legend
  horizontal = TRUE,
  proportional = TRUE,
  cpalette = sunset
)
```


```{r, fig.width=14, fig.height=12}
combined <- patchwork::wrap_plots(p1, p2, p3, ncol = 1) +
  patchwork::plot_layout(heights = c(1, 1, 2)) +
  patchwork::plot_annotation(
    title = "Frequency of Open Source Challenges",
    theme = theme(plot.title = element_text(
      size = 24,
      margin = margin(t = 15),
      hjust = 0.5)
      )
  )
combined
```

Actually, I think the cluster assignments might be stochastic? I.e., they are labeled randomly each time I run this script? I am too lazy to make sure that e.g. the cluster that contains "Documentation time" is always cluster #1. In fact, I think it would be poor practice to rename an intermediate data structure for the sake of the plot. I'd rather just change the plot titles. My solution is, I am just going to save the plot that I like, and not re-create it every time I run this script. Yes, this is less reproducible, but I'm not going to spend my time fixing it because it's a purely cosmetic problem that will only come up if someone tries to recreate my figures, and doesn't affect the underlying data.

```{r}
#save_plot("challenge_stacks.tiff", 14, 12, p=combined)
```

How does it look if we arrange these plots horizontally? We'll need to put the lenged on the right-most plot in this case.

```{r}
p2_hor <- stacked_bar_chart(
  df = data_cluster3,
  x_var = "challenge",
  y_var = "total",
  fill = "challenge_level",
  title = "Cluster 2", # NAME CHANGE, SEE TEXT ABOVE
  ylabel = NULL,
  show_legend = FALSE, # don't show legend
  show_axis_title_y = FALSE,
  show_x_axis_text = FALSE,
  show_grid = TRUE,
  horizontal = TRUE,
  proportional = TRUE,
  cpalette = sunset
)

p3_hor <- stacked_bar_chart(
  df = data_cluster1,
  x_var = "challenge",
  y_var = "total",
  fill = "challenge_level",
  title = "Cluster 3", # NAME CHANGE, SEE TEXT ABOVE
  ylabel = NULL,
  show_axis_title_y = FALSE,
  show_x_axis_text = FALSE,
  show_grid = TRUE,
  legend_left_margin = 45, # show legend, with a wide margin
  horizontal = TRUE,
  proportional = TRUE,
  cpalette = sunset
)
```

Tried plotting horizontally a couple different ways. I like the second way better, for now.

```{r, fig.width=14, fig.height=12}
# left column: p1 over p2; right column: p3 spanning full height
combined_hor <- patchwork::wrap_plots(
  (p1 / p2_hor / patchwork::plot_spacer()) + plot_layout(heights = c(1,1,0.1)) | p3_hor
) +
  #patchwork::plot_layout(heights = c(1, 1, 1)) +
  patchwork::plot_annotation(
    title = "Frequency of Open Source Challenges",
    theme = theme(
      plot.title = element_text(
        size = 24,
        margin = margin(t = 15),
        hjust = 0.5
      )
    )
  )
combined_hor
```

```{r, fig.width=15, fig.height=5}
# three plots in a row
combined_hor <- patchwork::wrap_plots(
  (p1 / patchwork::plot_spacer() ) + plot_layout(heights = c(1,1.4)) |
  (p2_hor / patchwork::plot_spacer() ) + plot_layout(heights = c(1,1.4)) | 
  p3_hor
) +
  #patchwork::plot_layout(heights = c(1, 1, 1)) +
  patchwork::plot_annotation(
    title = "Frequency of Open Source Challenges",
    theme = theme(
      plot.title = element_text(
        size = 24,
        margin = margin(t = 15),
        hjust = 0.5
      )
    )
  )
combined_hor
```

```{r}
save_plot("challenge_stacks_horizontal.tiff", 36, 8, p=combined_hor)
```

```{r}
sessionInfo()
```