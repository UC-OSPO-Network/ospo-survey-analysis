---
title: "Challenges + job category"
---

# Overview

Secondary analysis of survey Q9: "How frequently have you encountered the following challenges while working on open-source projects?"

In this script, I am considering challenges in light of job category.

## Import packages and utilities

```{r}
project_root <- here::here() # requires that you be somewhere in the
# project directory (not above it)
# packages
suppressMessages(source(file.path(project_root, "scripts/packages.R")))
# functions and objects used across scripts
suppressMessages(source(file.path(project_root, "scripts/utils.R")))
```


## Load data
```{r}
challenges <- load_qualtrics_data("clean_data/challenges_Q9.tsv")
other_quant <- load_qualtrics_data("clean_data/other_quant.tsv")
```

## Wrangle data
```{r}
challenges_and_job <- challenges
challenges_and_job$job_category <- other_quant$job_category

head(challenges_and_job)
```

Remove rows that contain any empty entries.
```{r}
nrow(challenges_and_job)
challenges_and_job <- exclude_empty_rows(challenges_and_job, strict = TRUE) # from scripts/utils.R
nrow(challenges_and_job)
```


For visual clarity in our plots, let's combine postdocs and other staff researchers, as well as undergrads and grad students.
```{r}
challenges_and_job <- challenges_and_job %>%
  mutate(
    job_category = recode(
      job_category,
      "Post-Doc" = "Postdocs and Staff Researchers",
      "Other research staff" = "Postdocs and Staff Researchers"
    )
  )

challenges_and_job <- challenges_and_job %>%
  mutate(
    job_category = recode(
      job_category,
      "Grad Student" = "Students",
      "Undergraduate" = "Students"
    )
  )

challenges_and_job$participantID <- row.names(challenges_and_job)

head(challenges_and_job)
```

Let's reshape the data from wide to long format for easier counting and plotting.

```{r}
long_data <- challenges_and_job %>%
  pivot_longer(
    cols = -c(participantID, job_category),
    names_to = "challenge",
    values_to = "challenge_level"
  )

long_data
```

# Top 5 challenges per group, by "points"

```{r}
long_data <- long_data %>%
  mutate(
    challenge_score = recode(
      challenge_level,
      "Never"           = 0L,
      "Non-applicable"  = 0L,
      "Rarely"          = 1L,
      "Occasionally"    = 2L,
      "Frequently"      = 3L,
      "Always"          = 4L
    )
  )
# Using interger literals 0L, 1L, etc., ensures that
# the new column will be integers, not doubles.

long_data
```

Let's just inspect all the basic stats for all the challenges for each group.

```{r}
# Helper to compute the (numeric) mode
get_mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}

get_summary_df <- function(job_str, df) {
  res <- df %>%
    filter(job_category == job_str) %>%
    group_by(challenge) %>%
    summarise(
      total = sum(challenge_score),
      mean = mean(challenge_score, na.rm = TRUE),
      median = median(challenge_score),
      mode = get_mode(challenge_score),
      st_dev = sd(challenge_score, na.rm = TRUE)
    ) %>%
    ungroup() %>%
    arrange(desc(total))
  return(res)
}
```

```{r}
jobs_ordered <- c(
  "Faculty",
  "Postdocs and Staff Researchers",
  "Students",
  "Non-research Staff"
)

summary_tables <- lapply(jobs_ordered, function(j) get_summary_df(j, long_data))
names(summary_tables) <- jobs_ordered
summary_tables
```

Let's plot the top 5. First, a little data wrangling.

```{r}
all_tbl <- bind_rows(summary_tables, .id = "job_category")

top5_by_job <- all_tbl %>%
  group_by(job_category) %>%
  slice_max(mean, n = 5, with_ties = FALSE) %>%
  ungroup() %>%
  select(job_category, challenge, mean) %>%
  mutate(job_category = factor(job_category, levels = jobs_ordered))

# Reorder factor levels for visual clarity
ordered_challenges_top5_by_points <- c(
  "Documentation time",
  "Coding time",
  "Education time",
  "Educational resources",
  "Securing funding",
  "Finding funding",
  "Managing issues",
  "Attracting users"
)                                                

top5_by_job$challenge <- factor(
  top5_by_job$challenge,
  levels = ordered_challenges_top5_by_points
)
```

Let's add a whitespace in this long job category name

```{r}
top5_by_job <- top5_by_job %>%
  mutate(
    job_category = recode(
      job_category,
      "Postdocs and Staff Researchers" = "Postdocs and\nStaff Researchers",
    )
  )
```

Let's hard-code a color palette that is tailored to these data. This will be useful in the next section, when we plot almost the same set of challenges, and we'll want the challenges to correspond to the same colors in the legend.
```{r}
# I'm just including the names here for my own reference,
# but they're not actually used in the code.
chall_colors <- list(
  # modified from https://sronpersonalpages.nl/~pault/
  "Documentation time" = "#332288",
  "Coding time" = "#88CCEE",
  "Education time" = "#44AA99",
  "Educational resources" = "#117733",
  "Securing funding" = "#999933",
  "Finding funding" = "#DDCC77",
  "Managing issues" = "#CC6677",
  "Attracting users" = "#882255"
)
```

```{r, fig.width=9, fig.height=6}
top5_by_points_plot <- ggplot(
  top5_by_job,
  aes(
    x = job_category,
    y = mean,
    fill = challenge
  )
) +
  geom_col(position = position_dodge()) +
  scale_fill_manual(values = chall_colors) +
  labs(
    x = "Job Category",
    y = "Mean Observed Rating\nFrom Coded Categories",
    fill = "Challenge",
    title = "Top 5 Challenges by Job Category (Points)"
  ) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 24),
    axis.text.x = element_text(angle = 60, vjust = 0.6, size = 18),
    axis.text.y = element_text(size = 18),
    axis.ticks.x = element_blank(),
    legend.title = element_blank(),
    legend.text = element_text(size = 18),
    panel.background = element_blank(),
    panel.grid = element_line(linetype = "solid", color = "gray90"),
    plot.title = element_text(hjust = 0, size = 24, face = "bold"),
    plot.margin = unit(c(0.3, 0.3, 0.3, 0.3), "cm")
  )
top5_by_points_plot
```

```{r}
save_plot("top5_challenges_by_job_points.tiff", 12, 10, p=top5_by_points_plot)
```


# Top 5 challenges per group, by proportion frequently or always

As another way of confirming/exploring these trends, let's look at the proportion of each group who said "frequently" or "always".
```{r}
# Calculate proportion of TRUEs by taking the mean of a logical vector,
# created by %in%.
proportions <- long_data %>%
  group_by(job_category, challenge) %>%
  summarize(proportion = mean(challenge_level %in% c("Frequently", "Always"))) %>%
  ungroup()
proportions
```

```{r}
top5_by_prop <- proportions %>%
  group_by(job_category) %>%
  slice_max(order_by = proportion, n = 5)
```

```{r}
# Filter to include only challenges present in the top5 dataframe 
filtered_props <- proportions %>%
  semi_join(top5_by_prop, by = c("job_category", "challenge"))
```

Let's inspect the challenges that made the cut. Are they the same as the challenges from calculating the top 5 the other way (by points)?
```{r}
ordered_challenges_top5_by_points
unique(filtered_props$challenge)
```

They are not the same. In this case, educational resources didn't make the cut. We can still use the same order of factor levels.

```{r}
# Reorder factor levels
filtered_props$challenge <- factor(
  filtered_props$challenge,
  levels = ordered_challenges_top5_by_points
)

filtered_props$job_category <- factor(
  filtered_props$job_category,
  levels = jobs_ordered
)
```

Let's add a whitespace in this long job category name

```{r}
filtered_props <- filtered_props %>%
  mutate(
    job_category = recode(
      job_category,
      "Postdocs and Staff Researchers" = "Postdocs and\nStaff Researchers",
    )
  )
```

Custom color palette, which doesn't contain "Educational resources"
```{r}
# I'm just including the names here for my own reference,
# but they're not actually used in the code.
chall_colors2 <- list(
  # modified from https://sronpersonalpages.nl/~pault/
  "Documentation time" = "#332288",
  "Coding time" = "#88CCEE",
  "Education time" = "#44AA99",
  #"Educational resources" = "#117733",
  "Securing funding" = "#999933",
  "Finding funding" = "#DDCC77",
  "Managing issues" = "#CC6677",
  "Attracting users" = "#882255"
)
```

```{r, fig.width=9, fig.height=6}
top5_by_perc_plot <- ggplot(
  filtered_props,
  aes(
    x = job_category,
    y = proportion,
    fill = challenge
  )
) +
  geom_col(position = position_dodge()) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  scale_fill_manual(values = chall_colors2) +
  labs(
    x = "Job Category",
    y = "Percent Saying\n'Frequently' or 'Always'",
    fill = "Challenge",
    title = "Top 5 Challenges by Job Category (Percent)"
  ) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_text(size = 24),
    axis.text.x = element_text(angle = 60, vjust = 0.6, size = 18),
    axis.text.y = element_text(size = 18),
    axis.ticks.x = element_blank(),
    legend.title = element_blank(),
    legend.text = element_text(size = 18),
    panel.background = element_blank(),
    panel.grid = element_line(linetype = "solid", color = "gray90"),
    plot.title = element_text(hjust = 0, size = 24, face = "bold"),
    plot.margin = unit(c(0.3, 0.3, 0.3, 0.3), "cm")
  )
top5_by_perc_plot
```

```{r}
save_plot("top5_challenges_by_job_percent.tiff", 12, 10, p=top5_by_perc_plot)
```

```{r}
p_combined <- patchwork::wrap_plots(
  top5_by_points_plot,
  plot_spacer(),
  top5_by_perc_plot
) +
  plot_layout(widths = c(1, 0.05, 1)) +
  theme(plot.margin = margin(t = 1, r = 1, b = 1, l = 1, unit = "cm"))
p_combined <- p_combined +
  plot_annotation(tag_levels = "A") &
  theme(plot.tag = element_text(size = 26))

# SVG is higher quality
svglite::svglite(
  file.path(FIGURE_PATH, "figureS7.svg"),
  width = 26,
  height = 10
)
print(p_combined)
dev.off()
```




# Consider clusters

## Exploratory plot

In a previous notebook, we found that the distributions of responses to the various challenges could be clustered like so:

Cluster 1:\
Education time\
Documentation time\
Coding time\

Cluster 2:\
Securing funding\
Hiring\
Finding funding\

Cluster 3:\
Everthing else

This makes me curious: does the distribution of job categories also vary by cluster? Before we try any statistics, let's just make a plot. This will be a variation of the detailed plot above.

We're just going to subset the "frequently" or "always" data to include only clusters 1 and 2, and we'll reorder the factor levels accordingly.

```{r}
clusters1and2 <- c(
  "Education time",
  "Documentation time",
  "Coding time",
  "Securing funding",
  "Finding funding",
  "Hiring"
)

to_plot_clusters <- subset(filtered_props, challenge %in% clusters1and2)

to_plot_clusters$challenge <- factor(
  to_plot_clusters$challenge,
  levels = clusters1and2
)
```

```{r, fig.width=9, fig.height=6}
challenges_plot_clusters1and2 <- ggplot(
  to_plot_clusters,
  aes(
    x = challenge,
    y = proportion,
    group = job_category,
    color = job_category,
    shape = job_category
  )
) +
  geom_point(size = 3) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  labs(
    x = "Challenge",
    y = "Proportion saying 'Frequently' or 'Always'",
    color = "Job Category",
    shape = "Job Category",
    title = "Proportion of respondents frequently facing challenges"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
challenges_plot_clusters1and2
```

Hm. Well, the results for cluster 1 are a little messy, which kind of makes sense, since you'd expect these to be challenges everyone struggles with. The only obvious trend to me is that undergrads struggle less than everyone else with education time and documentation time. But this group is too small to conclude anything with confidence.

Cluster 2 is a bit more interesting. It seems, at a glance, like it's pretty safe to say that faculty struggle with these challenges more than everyone else, with postdocs and staff researchers close behind.

I guess we should do a regression to test it.

# Regression for cluster 2

Let's once again combine the smaller groups to get more statistical power.

```{r}
cluster2data <- subset(
  long_data,
  challenge %in% c("Securing funding", "Finding funding", "Hiring")
)


cluster2data <- cluster2data %>%
  mutate(
    job_category = recode(
      job_category,
      "Post-Doc" = "Postdocs and Staff Researchers",
      "Other research staff" = "Postdocs and Staff Researchers"
    )
  )

cluster2data <- cluster2data %>%
  mutate(
    job_category = recode(
      job_category,
      "Grad Student" = "Students",
      "Undergraduate" = "Students"
    )
  )

cluster2data$challenge_level <- factor(cluster2data$challenge_level)

cluster2data
```

This code is really similar to code in solutions_stats.qmd. See that notebook for commentary on these models.

## Model 1: job_category * challenge interaction
```{r}
fit1 <- ordinal::clmm(challenge_level ~ job_category * challenge +      
              (1 | participantID),                 
            data = cluster2data, link = "logit", Hess = TRUE)
```

## Model 2: challenge as a random effect, no correlation between participant intercept and job effect
```{r}
fit2 <- ordinal::clmm(challenge_level ~ job_category +       
              (1 | challenge) +
              (1 | participantID) +
              (0 + job_category | challenge),                
            data = cluster2data, link = "logit", Hess = TRUE)
```

## Model 3: No job category
```{r}
fit3 <- ordinal::clmm(challenge_level ~ challenge +      
              (1 | participantID),                 
            data = cluster2data, link = "logit", Hess = TRUE)
```

## Model 4: No challenge category
```{r}
fit4 <- ordinal::clmm(challenge_level ~ job_category +      
              (1 | participantID),                 
            data = cluster2data, link = "logit", Hess = TRUE)
```


## Model 5: job_category + solution
```{r}
fit5 <- ordinal::clmm(challenge_level ~ job_category + challenge +
              (1 | participantID),                 
            data = cluster2data, link = "logit", Hess = TRUE)
```


## Model 6: no random effects
```{r}
# note clm function bc clmm is for mixed models
fit6 <- ordinal::clm(challenge_level ~ job_category * challenge,                 
            data = cluster2data, link = "logit", Hess = TRUE)
```


# Compare models
```{r}
models <- list(
  "fit1"=fit1, # job_category * challenge
  "fit2"=fit2, # challenge as random effect
  "fit3"=fit3, # Null model: no job
  "fit4"=fit4, # Null model: no challenge
  "fit5"=fit5, # Null model: no interaction
  "fit6"=fit6 # Null model: no participants
)
```

```{r}
sapply(models, function(x) round(stats::AIC(x)))
```

Models 1 and 5 look best in terms of AIC.

Let's check the condition number of the Hessian. I don't really understand what this is, but the clmm2 tutorial says that high numbers, say larger than say 10^4 or 10^6, indicate poor fit.
```{r}
sapply(models, function(x) 
summary(x)$info["cond.H"]
)
```

All look ok.

## Complex models vs null models

Let's use an anova to compare nested models.
```{r}
stats::anova(fit1, fit5)
```

Interesting, that p-value is not significant. So it appears the interaction term is not needed.

Let's also double-check that participants are worth including.
```{r}
stats::anova(fit1, fit6)
```
Yes, it appears they are.


Does it matter whether we include job as a variable? Let's compare it to the model without an interaction term.
```{r}
stats::anova(fit3, fit5)
```
Yes, including job improves model fit.

So far, fit5 is the one to beat.

## More goodness-of-fit tests

SEs of the coefficients
```{r}
summary(fit5$coefficients)
summary(fit2$coefficients)
```

These look pretty similar.

Let's do one more diagnostic. fit6 is the equivalent model to fit1b, but with fixed effects only. Since we can do the nominal_test and scale_test on this model, let's try it and see if it sets off any red flags.

```{r}
nominal_test(fit6)
scale_test(fit6)
```

Boo. The model with no random effects has violations to both assumptions.

Ouch. That's not ideal. Maybe we can proceed with caution, and follow up with a non-parametric test on whatever trends we find? https://www.fharrell.com/post/po/

# EMMs

Again, see the solutions_stats notebook for more detail on this.

```{r}
emm <- summary(emmeans(fit5, ~ challenge | job_category, mode = "mean.class"))
emm
```

# Pairwise comparisons and p-values

Here we look at pairwise contrasts by challenge.
```{r}
emm2 <- emmeans(fit5, ~ job_category | challenge, mode = "mean.class")
by_chall <- summary(
  pairs(emm2, by = "challenge"),
  infer = TRUE # infer CIs
) 

by_chall
```

Wow, the p-values are really similar across the board. Faculty rate these challenges higher than students and NR staff, but not higher than postdocs and staff researchers.

# Kruskal-Wallis test for ranking differences between groups

Non-parametric test for the extent of disagreement between groups. Whereas above, we tested for differences in mean ratings, here we are testing for differences in the distributions of ratings for each solution.

```{r}
cluster2data_numcoded <- cluster2data %>%
  mutate(
    challenge_score = recode(
      challenge_level,
      "Non-applicable" = 0L,
      "Never" = 0L,
      "Rarely" = 1L,
      "Occasionally" = 2L,
      "Frequently" = 3L,
      "Always" = 4L
    )
  )

cluster2data_numcoded$job_category <- factor(cluster2data_numcoded$job_category)

kw_results <- sapply(split(cluster2data_numcoded, cluster2data_numcoded$challenge), function(df) {
  kruskal.test(challenge_score ~ job_category, data = df)$p.value
})

p_adj_kw <- p.adjust(kw_results, "BH")

p_adj_kw < 0.05
sum(p_adj_kw < 0.05)
```

Ok, so K-W test indicates that for all three challenges, there are differences between the groups.

Dunn test as a post-hoc test to see which groups are different from each other.

```{r}
pairwise_results <- lapply(unique(cluster2data_numcoded$challenge), function(chall) {
  df <- subset(cluster2data_numcoded, challenge == chall)
  out <- FSA::dunnTest(challenge_score ~ job_category, data = df, method = "bh")
  cbind(challenge = chall, out$res)
})
pairwise_results <- do.call(rbind, pairwise_results)
```

Let's print the significant pairs.
```{r}
subset(pairwise_results, P.adj < 0.05)
```

And the non-significant pairs
```{r}
subset(pairwise_results, P.adj >= 0.05)
```

Cool. In all three cases, faculty are significantly different from NR staff and students.

```{r}
sessionInfo()
```